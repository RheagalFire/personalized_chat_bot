{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86940c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be62a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_key = #your open_ai_key goes here\n",
    "openai.api_key = open_ai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9db6257e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arish\\AppData\\Roaming\\pypoetry\\venv\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "# initialize connection to pinecone\n",
    "pinecone_key = #your pinecone_key goes here\n",
    "pinecone.init(\n",
    "    api_key=pinecone_key,  # app.pinecone.io (console)\n",
    "    environment=\"eu-west1-gcp\"  # next to API key in console\n",
    ")\n",
    "index_name = 'personalized-bot'\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e84b91c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "embed_model = \"text-embedding-ada-002\"\n",
    "query = \"Food preferences\"\n",
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "xq = res['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51b3974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = index.query(xq, top_k=10, include_metadata=True,namespace='text_field_9')\n",
    "\n",
    "contexts = [item['metadata']['text'] for item in result['matches']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c25d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = \"\"\"\n",
    "Using the provided conversation data between two persons, your task is to emulate the speaking style and language of one of the individuals while answering the user's question.\n",
    "Draw upon your own knowledge and training to provide relevant and informative responses, but ensure that your answers reflect the mannerisms, tone, and language used by the chosen person. \n",
    "Always respond in the language of the conversation data shared, regardless of the question asked.\n",
    "Chosen person is\n",
    "\"\"\"\n",
    "\n",
    "string2 = \"\"\"\n",
    "{chat_history}\n",
    "human:{human_input}\n",
    "Chatbot:\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ba73e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_person = \"Aarish\"\n",
    "primer = string1 + current_person + string2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04bcf466",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\",\"human_input\"],\n",
    "    template=primer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0adbd671",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=open_ai_key,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eeeb9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1395e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ee4797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_query = 'kya khana hai?'\n",
    "augmented_query = \"\\n\\n---\\n\\n\".join(contexts)+\"\\n\\n-----\\n\\n\"+ input_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a507071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Using the provided conversation data between two persons, your task is to emulate the speaking style and language of one of the individuals while answering the user's question.\n",
      "Draw upon your own knowledge and training to provide relevant and informative responses, but ensure that your answers reflect the mannerisms, tone, and language used by the chosen person. \n",
      "Always respond in the language of the conversation data shared, regardless of the question asked.\n",
      "Chosen person is\n",
      "Aarish\n",
      "\n",
      "human:\n",
      "\n",
      "-----\n",
      "\n",
      "kya khana hai?\n",
      "Chatbot:\"\"\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAarish bhaiya humein kuch chatpata khana chahiye. Humare paas bahut saare options hai jaise Pani Puri, Bhel Puri, Dahi Puri, Aloo Tikki, Samosa aur bahut kuch. Kya aapko kuch pasand hai?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=augmented_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "350b5d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arish\\AppData\\Roaming\\pypoetry\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa92e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
